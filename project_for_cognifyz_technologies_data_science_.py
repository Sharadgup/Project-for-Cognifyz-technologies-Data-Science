# -*- coding: utf-8 -*-
"""Project for Cognifyz technologies Data Science  .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18E7y7Bmslnqp-aO4spPWowHbB9q01odk

#Welcome to our exciting Data Science internship program! To complete this internship, you will have
the chance to choose any 2 of 3 levels: Level 1, Level 2, or Level 3. We've designed these levels to
cater to your convenience and ensure an engaging and rewarding experience. Additionally, the
successful completion of Level 3 ( any 2 task out of 4) will further enhance your chances of receiving
# a stipend.

# #Data Exploration and Preprocessing
Explore the dataset and identify the number
of rows and columns.
Check for missing values in each column and
handle them accordingly.
Perform data type conversion if necessary.
Analyze the distribution of the target variable
("Aggregate rating") and identify any class
imbalances.
# New Section
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pandas

import pandas as pd

file_path = 'https://drive.google.com/u/0/uc?id=1eS-q31uXdtdpSOg15g7SZ65rZjBM7gBO&export=download'

df = pd.read_csv(file_path)

df.head()

"""#Data Clearing with explorting ."""

# Check column names, data types, and missing values
print(df.info())

# Identify the number of rows and columns
print("Number of rows:", df.shape[0])
print("Number of columns:", df.shape[1])

# Check for missing values in each column
print(df.isnull().sum())

"""# ** Descriptive Analysis
Calculate basic statistical measures (mean,
median, standard deviation, etc.) for numerical
columns.
Explore the distribution of categorical
variables like "Country Code,
" "City,
" and
"Cuisines.
"
Identify the top cuisines and cities with the
highest number of restaurants.**
"""

# Analyze distribution of the target variable
numerical_stats= (df['Aggregate rating'].describe())

# Example: Visualize the distribution using a histogram
import matplotlib.pyplot as plt

plt.hist(df['Aggregate rating'], bins=10)
plt.xlabel('Aggregate rating')
plt.ylabel('Frequency')
plt.title('Distribution of Aggregate Ratings')
plt.show()

print(numerical_stats)

# Explore distribution of categorical variables
country_counts = df['Country Code'].value_counts()
city_counts = df['City'].value_counts()
cuisine_counts = df['Cuisines'].value_counts()

print("Country Code distribution:")
print(country_counts)

print("City distribution:")
print(city_counts)

print("Cuisines distribution:")
print(cuisine_counts)

# Identify top cuisines and cities
top_cuisines = df['Cuisines'].value_counts().head(10)
top_cities = df['City'].value_counts().head(10)

print("Top Cuisines:")
print(top_cuisines)

print("Top Cities:")
print(top_cities)

"""Geospatial Analysis
Visualize the locations of restaurants on a
map using latitude and longitude
information.
Analyze the distribution of restaurants
across different cities or countries.
Determine if there is any correlation
between the restaurant's location and its
rating.

"""

import pandas as pd
import folium
from IPython.display import HTML

# Create a map centered on the first location in your dataset (adjust as needed)
first_location = df.iloc[0]  # Assuming the first row contains latitude and longitude
map_center = [first_location['Latitude'], first_location['Longitude']]

# Create the map centered on the first location
my_map = folium.Map(location=map_center, zoom_start=10)

# Add markers for each location in your dataset
for index, row in df.iterrows():
    folium.Marker([row['Latitude'], row['Longitude']], popup=row['Restaurant Name']).add_to(my_map)

# Generate the HTML content of the map
map_html = my_map._repr_html_()

# Display the map in Google Colab using HTML
HTML(map_html)

# Analyze distribution across cities
city_distribution = df.groupby('City').size()
print("Restaurant distribution across cities:")
print(city_distribution)

# Analyze distribution across countries
country_distribution = df.groupby('Country Code').size()
print("Restaurant distribution across countries:")
print(country_distribution)

# Calculate correlation between location (latitude, longitude) and rating
location_rating_corr = df[['Latitude', 'Longitude', 'Aggregate rating']].corr()
print("Correlation between location and rating:")
print(location_rating_corr)

"""Task: Table Booking and Online Delivery
Determine the percentage of restaurants that
offer table booking and online delivery.
Compare the average ratings of restaurants
with table booking and those without.
Analyze the availability of online delivery
among restaurants with different price ranges.
"""

# Convert 'Has Table Booking' and 'Has Online Delivery' columns to numeric format
df['Has Table booking'] = df['Has Table booking'].replace({'Yes': 1, 'No': 0})
df['Has Online delivery'] = df['Has Online delivery'].replace({'Yes': 1, 'No': 0})

# Calculate percentage of restaurants offering table booking
table_booking_percentage = (df['Has Table booking'].sum() / len(df)) * 100
print("Percentage of restaurants offering table booking:", table_booking_percentage)

# Calculate percentage of restaurants offering online delivery
online_delivery_percentage = (df['Has Online delivery'].sum() / len(df)) * 100
print("Percentage of restaurants offering online delivery:", online_delivery_percentage)

# Compare average ratings of restaurants with and without table booking
avg_rating_with_table_booking = df[df['Has Table booking'] == 'Yes']['Aggregate rating'].mean()
avg_rating_without_table_booking = df[df['Has Table booking'] == 'No']['Aggregate rating'].mean()

print("Average rating of restaurants with table booking:", avg_rating_with_table_booking)
print("Average rating of restaurants without table booking:", avg_rating_without_table_booking)

# Group by price range and calculate the percentage of restaurants offering online delivery
online_delivery_by_price_range = df.groupby('Price range')['Has Online delivery'].apply(lambda x: (x == 'Yes').sum() / len(x) * 100)
print("Online delivery availability by price range:")
print(online_delivery_by_price_range)

"""Task: Price Range Analysis
Determine the most common price range
among all the restaurants.
Calculate the average rating for each price
range.
Identify the color that represents the highest
average rating among different price ranges.
"""

# Determine the most common price range
most_common_price_range = df['Price range'].mode()[0]
print("Most common price range:", most_common_price_range)

# Calculate average rating for each price range
avg_rating_by_price_range = df.groupby('Price range')['Aggregate rating'].mean()
print("Average rating by price range:")
print(avg_rating_by_price_range)

# Identify the color representing the highest average rating
highest_avg_rating_color = avg_rating_by_price_range.idxmax()
print("Color representing the highest average rating:", highest_avg_rating_color)

import pandas as pd
import matplotlib.pyplot as plt

# Assuming you have already calculated avg_rating_by_price_range from the previous code
# If not, you can use the code snippet provided in the previous message

# Plotting the scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(avg_rating_by_price_range.index, avg_rating_by_price_range, c=avg_rating_by_price_range, cmap='viridis', s=100)

# Adding labels and title
plt.xlabel('Price Range')
plt.ylabel('Average Rating')
plt.title('Average Rating by Price Range')

# Adding color bar
cbar = plt.colorbar()
cbar.set_label('Average Rating Color')

# Identifying the highest average rating and its corresponding color
highest_avg_rating = avg_rating_by_price_range.max()
highest_avg_rating_color = avg_rating_by_price_range.idxmax()

# Highlighting the point with the highest average rating
plt.scatter(highest_avg_rating_color, highest_avg_rating, color='red', s=150, label=f'Highest Avg Rating: {highest_avg_rating:.2f}')

# Adding legend
plt.legend()

# Show the plot
plt.grid(True)
plt.tight_layout()
plt.show()

"""Task: Feature Engineering
Extract additional features from the existing
columns, such as the length of the restaurant
name or address.
Create new features like "Has Table Booking"
or "Has Online Delivery" by encoding
categorical variables.
"""

# Extract additional features: Name Length and Address Length
df['Name Length'] = df['Restaurant Name'].apply(len)
df['Address Length'] = df['Address'].apply(len)

# Display the updated DataFrame with new features
print(df.head())

# One-hot encoding for 'Has Table Booking' and 'Has Online Delivery'
df['Has Table booking (Encoded)'] = pd.get_dummies(df['Has Table booking'], drop_first=True)
df['Has Online delivery (Encoded)'] = pd.get_dummies(df['Has Online delivery'], drop_first=True)

# Display the updated DataFrame with encoded features
print(df.head())

from sklearn.preprocessing import MinMaxScaler

# Initialize MinMaxScaler
scaler = MinMaxScaler()

# Normalize numerical features (e.g., Name Length and Address Length)
df[['Name Length', 'Address Length']] = scaler.fit_transform(df[['Name Length', 'Address Length']])

# Display the normalized DataFrame
print(df.head())

"""Task: Predictive Modeling
Build a regression model to predict the
aggregate rating of a restaurant based on
available features.
Split the dataset into training and testing sets
and evaluate the model's performance using
appropriate metrics.
Experiment with different algorithms (e.g.,
linear regression, decision trees, random
forest) and compare their performance.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.impute import SimpleImputer

# Assuming your dataset is already preprocessed and contains X (features) and y (target variable)
X = df[['Rating color', 'Name Length','Has Table booking','Has Online delivery','Restaurant Name','Locality' ,'City']]  # Specify the relevant features
y = df['Aggregate rating']  # Target variable

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Handle categorical variables (one-hot encoding)
encoder = OneHotEncoder(handle_unknown='ignore')
X_train_encoded = encoder.fit_transform(X_train[['Rating color', 'City']])
X_test_encoded = encoder.transform(X_test[['Rating color', 'City']])

# Impute missing values if any
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train_encoded)
X_test_imputed = imputer.transform(X_test_encoded)

# Initialize regression models
linear_reg = LinearRegression()
decision_tree_reg = DecisionTreeRegressor(random_state=42)
random_forest_reg = RandomForestRegressor(random_state=42)

# Train the models
linear_reg.fit(X_train_imputed, y_train)
decision_tree_reg.fit(X_train_imputed, y_train)
random_forest_reg.fit(X_train_imputed, y_train)

# Make predictions on the testing data
y_pred_linear = linear_reg.predict(X_test_imputed)
y_pred_tree = decision_tree_reg.predict(X_test_imputed)
y_pred_forest = random_forest_reg.predict(X_test_imputed)

# Evaluate model performance
def evaluate_model(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return mae, mse, r2

mae_linear, mse_linear, r2_linear = evaluate_model(y_test, y_pred_linear)
mae_tree, mse_tree, r2_tree = evaluate_model(y_test, y_pred_tree)
mae_forest, mse_forest, r2_forest = evaluate_model(y_test, y_pred_forest)

print("Linear Regression Metrics:")
print("MAE:", mae_linear)
print("MSE:", mse_linear)
print("R-squared:", r2_linear)

print("\nDecision Tree Regression Metrics:")
print("MAE:", mae_tree)
print("MSE:", mse_tree)
print("R-squared:", r2_tree)

print("\nRandom Forest Regression Metrics:")
print("MAE:", mae_forest)
print("MSE:", mse_forest)
print("R-squared:", r2_forest)

# Compare model performance
print("Decision Tree Regression Metrics:")
print("MAE:", mae_tree)
print("MSE:", mse_tree)
print("R-squared:", r2_tree)

print("Random Forest Regression Metrics:")
print("MAE:", mae_forest)
print("MSE:", mse_forest)
print("R-squared:", r2_forest)

import pickle

# Save the best performing model (Random Forest in this case) to a pickle file
best_model = random_forest_reg
filename = 'restaurant_rating_prediction_model.pkl'
with open(filename, 'wb') as file:
    pickle.dump(best_model, file)

print(f"\nBest performing model (Random Forest) saved to {filename}")

from google.colab import drive
import pickle

# Mount Google Drive
drive.mount('/content/drive')

# Assuming your model is already trained and saved as 'restaurant_rating_prediction_model.pkl'
# Specify the path to save the pickle file in Google Drive
pickle_file_path = '/content/drive/My Drive/Colab Notebooks/restaurant_rating_prediction_model.pkl'

# Save the model to Google Drive
with open(pickle_file_path, 'wb') as file:
    pickle.dump(best_model, file)

print(f"Model saved to Google Drive: {pickle_file_path}")

"""Task: Customer Preference Analysis
Analyze the relationship between the type of
cuisine and the restaurant's rating.
Identify the most popular cuisines among
customers based on the number of votes.
Determine if there are any specific cuisines
that tend to receive higher ratings
"""

import pandas as pd
import matplotlib.pyplot as plt

# Data Exploration
print(df.head())  # Display the first few rows to understand the data structure
print(df.info())  # Check for missing values and data types

# Analyze Cuisine-Rating Relationship
avg_rating_by_cuisine = df.groupby('Cuisines')['Aggregate rating'].mean().sort_values(ascending=False)
print("Average Rating by Cuisine Type:")
print(avg_rating_by_cuisine)

# Optionally, plot the average ratings by cuisine
plt.figure(figsize=(10, 6))
avg_rating_by_cuisine.plot(kind='bar')
plt.xlabel('Cuisines')
plt.ylabel('Average Rating')
plt.title('Average Rating by Cuisine Type')
plt.xticks(rotation=45)
plt.show()

# Identify Popular Cuisines
popular_cuisines = df.groupby('Cuisines')['Votes'].sum().sort_values(ascending=False)
print("Popular Cuisines based on Number of Votes:")
print(popular_cuisines.head())

# Optionally, plot the number of votes for each cuisine
plt.figure(figsize=(10, 6))
popular_cuisines.head(10).plot(kind='bar')
plt.xlabel('Cuisines')
plt.ylabel('Number of Votes')
plt.title('Top 10 Popular Cuisines based on Number of Votes')
plt.xticks(rotation=45)
plt.show()

# Analyze High-Rating Cuisines
high_rating_cuisines = df[df['Aggregate rating'] >= 4.0]  # Filter restaurants with rating >= 4.0
avg_rating_high_rating = high_rating_cuisines.groupby('Cuisines')['Aggregate rating'].mean().sort_values(ascending=False)
print("Average Rating of High-Rating Cuisines:")
print(avg_rating_high_rating)

# Optionally, plot the average ratings of high-rating cuisines
plt.figure(figsize=(10, 6))
avg_rating_high_rating.plot(kind='bar')
plt.xlabel('Cuisines')
plt.ylabel('Average Rating')
plt.title('Average Rating of High-Rating Cuisines')
plt.xticks(rotation=45)
plt.show()

"""Task: Data Visualization
Create visualizations to represent the distribution
of ratings using different charts (histogram, bar
plot, etc.).
Compare the average ratings of different cuisines
or cities using appropriate visualizations.
Visualize the relationship between various
features and the target variable to gain insights.

"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Distribution of Ratings
plt.figure(figsize=(8, 6))
plt.hist(df['Rating color'], bins=5, color='skyblue', edgecolor='black', alpha=0.7)
plt.xlabel('Rating color')
plt.ylabel('Count')
plt.title('Distribution of Ratings')
plt.show()

# Comparing Average Ratings by Cuisine
avg_rating_by_cuisine = df.groupby('Cuisines')['Aggregate rating'].mean().sort_values(ascending=False)
plt.figure(figsize=(12, 6))
ax1 = avg_rating_by_cuisine.plot(kind='bar', color='salmon')
ax1.set_xlabel('Cuisine')
ax1.set_ylabel('Average Rating')
ax1.set_title('Average Rating by Cuisine Type')
plt.xticks(rotation=45)
for i, val in enumerate(avg_rating_by_cuisine.values):
    plt.text(i, val, round(val, 2), ha='center', va='bottom', fontsize=9)
plt.tight_layout()
plt.show()

# Comparing Average Ratings by City
avg_rating_by_city = df.groupby('City')['Aggregate rating'].mean().sort_values(ascending=False)
plt.figure(figsize=(14, 6))
ax2 = sns.barplot(x=avg_rating_by_city.index, y=avg_rating_by_city.values, palette='viridis')
ax2.set_xlabel('City')
ax2.set_ylabel('Average Rating')
ax2.set_title('Average Rating by City')
plt.xticks(rotation=90)
for p in ax2.patches:
    ax2.annotate(f'{p.get_height():.2f}', (p.get_x() + p.get_width() / 2., p.get_height()),
                 ha='center', va='center', fontsize=9, color='black', xytext=(0, 5),
                 textcoords='offset points')
plt.tight_layout()
plt.show()

# Visualizing Relationship with Target Variable
# For example, let's visualize the relationship between 'Votes' and 'Aggregate rating'
plt.figure(figsize=(10, 8))
sns.scatterplot(x='Votes', y='Aggregate rating', data=df, alpha=0.5)
plt.xlabel('Votes')
plt.ylabel('Aggregate Rating')
plt.title('Relationship between Votes and Aggregate Rating')
plt.xticks(rotation=45)
plt.yticks(rotation=45)
plt.tight_layout()
plt.show()

"""Thank You I am Completely the Task."""